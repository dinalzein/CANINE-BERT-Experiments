{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CANINE vs BERT on COLA\n",
        "\n"
      ],
      "metadata": {
        "id": "fDTXNWgEHNr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this notebook, we will use the pre-trained CANINE model to fine-tune a a binary classification NLP task that predicts whether or not an English sentence is grammatically correct and we compare its performance against BERT. We will use [CoLA](https://nyu-mll.github.io/CoLA/), a corpus consisting of $10657$ English sentences associated with a label that tells if the sentence is grammatically correct.**\n",
        "\n",
        "**Notebook adapted from [Hugging face text classififcation guide](https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb)**"
      ],
      "metadata": {
        "id": "FmyzkrHMGML6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "T4v2biUx8xQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount on google drive**"
      ],
      "metadata": {
        "id": "UVRluHvVHScc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount= True)\n",
        "Folder_name = 'MVA_NLP'\n",
        "assert Folder_name is not None, \"[1] Enter the folder name\"\n",
        "\n",
        "import sys \n",
        "sys.path.append('content/drive/MyDrive/{}'.format(Folder_name))\n",
        "%cd drive/MyDrive/$Folder_name/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvqSKN3PcT7e",
        "outputId": "cbfba4f2-3d95-4211-a17c-0a1552f41313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/MVA_NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check GPU**"
      ],
      "metadata": {
        "id": "1TF_09jjOMyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "1lP2Jm4lOPtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install**"
      ],
      "metadata": {
        "id": "5V6SzPPSH8TA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "outputs": [],
      "source": [
        "! pip install datasets transformers\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports** "
      ],
      "metadata": {
        "id": "ViYgYz-J3ndx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GI1nWSma3uZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "RvfOR2QmL6dN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading [CoLA](https://nyu-mll.github.io/CoLA/) Dataset**"
      ],
      "metadata": {
        "id": "UxH7KoT6L9up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric"
      ],
      "metadata": {
        "id": "UkfDb67RMSiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"cola\"\n",
        "dataset = load_dataset(\"glue\", task)\n",
        "\n",
        "dataset "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQPGNxpDNPTZ",
        "outputId": "a7a66bdf-9a90-4e2b-f7c4-1b2888db324f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 8551\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1043\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1063\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To have a look on how the dataset looks like**"
      ],
      "metadata": {
        "id": "_uHvz-wfN6k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "sb69Y63sN-iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "lDKIb9iZUgmI",
        "outputId": "3b74c149-6cb8-4dcf-8a71-888ab54aabe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two miles are as far as they can walk.</td>\n",
              "      <td>unacceptable</td>\n",
              "      <td>4161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He has left.</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the classroom, the teacher praised John, whom I also respect.</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>4941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who did that Plato loved seem to be known by everyone.</td>\n",
              "      <td>unacceptable</td>\n",
              "      <td>8054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The excellent whisky which I went to the store and have bought was very costly.</td>\n",
              "      <td>unacceptable</td>\n",
              "      <td>1282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The man arrived on the train was my brother.</td>\n",
              "      <td>unacceptable</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>John saw more horses than Bill saw cows or Pete talked to cats.</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>6558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Emma and Harriet were attacked by those bandits.</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>6964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I searched for treasure in the cave.</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>3023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The apple was bitten by John.</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>5940</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning a model on CoLA:**\n",
        "\n",
        "**We will use the pre-trained CANINE models: CANINE-C (Canine with character loss), CANINE-S (Canine with subwords loss) and BERT (bert-base-uncased) to fine-tune it on CoLA.**\n",
        "\n",
        "**CANINE-C is pre-trained with autoregressive character loss, $12$-layer, $768$-hidden, $12$-heads, $121M$ parameters.**\n",
        "\n",
        "**CANINE-S is pre-trained with subword loss, $12$-layer, $768$-hidden, $12$-heads, $121M$ parameters.**\n",
        "\n",
        "**BERT, bert-base-uncased, is pretrained on lower-cased English text that consists of $12$-layers, $768$-hidden, $12$-heads, and $110M$ parameters.**\n",
        "\n",
        "**In this notebook, we are using CANINE-C but to use other models, you just need to change the value of the `model_checkpoint` to `model_checkpoint = \"google/canine-s\"` for CANINE-S and `model_checkpoint = \"bert-base-uncased\"` for BERT.** \n",
        "\n",
        "**The results for all the models are presnted in the report attached to this notebook.**  \n",
        "\n"
      ],
      "metadata": {
        "id": "rVMBa4iUP1o8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"google/canine-c\"\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "urram1OkUeCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Dataset**"
      ],
      "metadata": {
        "id": "t1D7nhSGSD17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "#choose a tokenizer that works with the model chosen.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "metadata": {
        "id": "PMoifwqSTzZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_key = \"sentence\"\n",
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples[task_key], truncation=True)\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "02be246af64c4c82b7004217144d61d2",
            "5d7496d0d66749e7904865b5d00d2899",
            "3c594033badb4267bbf3694fe6dd1062",
            "50df72f44a2f4c49b33f28d47226635f",
            "396e9763ab254227bcf345068de90bc9",
            "77521db7ddb54f0198f63dc4938e3af7",
            "adf8947925894b89803b23ae282fa29b",
            "aab64adc47584295a6d9fb77a563cd65",
            "11c72992c7a2416eaac88da8a4a72c22",
            "8788a8a276654e2da0279c396791b44f",
            "adc757921aea4faea796417c1a120abc",
            "22d436eda08748beab0645da61c29bbc",
            "6ab4beef4d324b2aac786cd7aa07f01f",
            "13e2577fb58d4e7eae5c813438fab530",
            "961bbaa500e741f5a7b6b895fd9d9343",
            "ca6cbf7cf2ec4aa39edf2c9961ef61b6",
            "fe4fa0dd6bc844e191de3f877a936600",
            "5533ae797aa54dfab8eda42dfb39f997",
            "8f22547f55a24852901bdc7ddd7728ed",
            "3268f2b7e79344e29613341e167142f4",
            "8eb3287358014d259dca90477cb4b0d3",
            "ac1ef07541404f4e981423a73695e341",
            "63a8ca7ce5cb4633acfd7a806ffadb71",
            "5d4805015b734505bf41675b9583e9e7",
            "e276b589bc1141b9b8f4a2178740b9d2",
            "b5189dbedf914989a9ae731b199be6b2",
            "83f17266ffb045b3a650f20d4d1a4a2d",
            "df42a620ea4148b9a4226e9db3874980",
            "caf533fe81d242358deeaa205f2a8fe0",
            "44abe24f331e4620b4023114a9ca345c",
            "a09ec2f6c03b4810833da26265f4767b",
            "1e7d8e1d1d5e4083b642c1746fdc3698",
            "579a41fb139e4923a7c36dc9d1d30a9f"
          ]
        },
        "id": "eeun2B6dWF7r",
        "outputId": "cbf1b075-248d-41b1-d49b-4aa1421e12bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02be246af64c4c82b7004217144d61d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22d436eda08748beab0645da61c29bbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63a8ca7ce5cb4633acfd7a806ffadb71"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "RI-uaEZAMpDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the metric we want to evaluate our model on. The metric asscoiated with the CoLA task is Matthews Correlation Coefficient. \n",
        "For more information on how this metric works, check: [Matthews Correlation Coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient).**\n"
      ],
      "metadata": {
        "id": "05R7p8hhUVLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_name = \"matthews_correlation\" \n",
        "metric = load_metric('glue', task)\n",
        "metric "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBdwy-OfOi2C",
        "outputId": "9555d9b9-2eb3-42da-c956-d0fd7677b3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
              "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
              "Args:\n",
              "    predictions: list of predictions to score.\n",
              "        Each translation should be tokenized into a list of tokens.\n",
              "    references: list of lists of references for each translation.\n",
              "        Each reference should be tokenized into a list of tokens.\n",
              "Returns: depending on the GLUE subset, one or several of:\n",
              "    \"accuracy\": Accuracy\n",
              "    \"f1\": F1 score\n",
              "    \"pearson\": Pearson Correlation\n",
              "    \"spearmanr\": Spearman Correlation\n",
              "    \"matthews_correlation\": Matthew Correlation\n",
              "Examples:\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
              "    >>> references = [0, 1]\n",
              "    >>> predictions = [0, 1]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'accuracy': 1.0}\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
              "    >>> references = [0, 1]\n",
              "    >>> predictions = [0, 1]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'accuracy': 1.0, 'f1': 1.0}\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
              "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
              "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
              "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
              "    >>> references = [0, 1]\n",
              "    >>> predictions = [0, 1]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'matthews_correlation': 1.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "#Fine-tuning the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "outputId": "f940cf13-bc68-46cd-e7dc-d8e6669e5ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "0b62c71425ee47318fd87e51c640b64e",
            "e89f52edb7114bf988c4bddcebcc8f2f",
            "d4f7dc2bb0024550bf4b8a301115fa6f",
            "e15a870a82e4496cb95aec1e117e4adc",
            "a27ce3800d124daf8681dbd03a619c1f",
            "ca15adc9f8714c5cb9028d310b51eed3",
            "e9e5e782c9884e45847566e3498c8a75",
            "711c1c38b82b4f63966736c78e74924e",
            "c57762f9b1df4544bff2375d4785825d",
            "9a9a618ad0c3458d8ef55ae22486b37f",
            "f9993594943f4396be26018c9f3c0667",
            "144464a357b64a30a8accf75bdc729f8",
            "8d155b5340c749478244f73604af1dad",
            "0c55b5326dc441de9eb2e8f8a3720e99",
            "7f12148a7e824024aa65e8f1feaef953",
            "d147c794ec05440dbe9a02988e4264d2",
            "ea710aa1e3c044f8afe7e35723711bf2",
            "d187d2d9751d4a43b37fbb247c88b2a8",
            "43b8cb7525474850898c927dbc428cbe",
            "6c28371db2764cbba3c3d973508c1e57",
            "a24849132db94f6b8142644852645df2",
            "d9ddac17da494652becfebbbe045b6e6"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/698 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b62c71425ee47318fd87e51c640b64e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/504M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "144464a357b64a30a8accf75bdc729f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "num_labels = 2 \n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bliy8zgjIrJY"
      },
      "outputs": [],
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-{task}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmvbnJ9JIrJd"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imY1oC3SIrJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4bce5d-d546-4d21-bce5-0c454c28a798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning https://huggingface.co/dinalzein/canine-c-finetuned-cola into local empty directory.\n"
          ]
        }
      ],
      "source": [
        "validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[validation_key],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "outputId": "2d8f8f0b-5dc1-4f8a-8714-d53fc8672dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2675\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2675' max='2675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2675/2675 05:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.613600</td>\n",
              "      <td>0.639571</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.608600</td>\n",
              "      <td>0.617789</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.612700</td>\n",
              "      <td>0.617412</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.595700</td>\n",
              "      <td>0.621486</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.567700</td>\n",
              "      <td>0.668877</td>\n",
              "      <td>0.064819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-535\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-535/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-535/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-535/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-535/special_tokens_map.json\n",
            "tokenizer config file saved in canine-c-finetuned-cola/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-1070\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-1070/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-1070/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-1070/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-1070/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-1605\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-1605/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-1605/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-1605/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-1605/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-2140\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-2140/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-2140/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-2140/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-2140/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-2675\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-2675/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-2675/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-2675/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-2675/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/checkpoint-2675 (score: 0.06481858054613046).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2675, training_loss=0.595980549749927, metrics={'train_runtime': 330.9922, 'train_samples_per_second': 129.172, 'train_steps_per_second': 8.082, 'total_flos': 2378238037956300.0, 'train_loss': 0.595980549749927, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOUcBkX8IrJi",
        "outputId": "ea4029c4-2b73-4524-df20-5c8b672f7c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [66/66 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_loss': 0.6688772439956665,\n",
              " 'eval_matthews_correlation': 0.06481858054613046,\n",
              " 'eval_runtime': 1.9749,\n",
              " 'eval_samples_per_second': 528.125,\n",
              " 'eval_steps_per_second': 33.419}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffP-VQOyIrJk"
      },
      "source": [
        "**To see how your model performed you can compare it to the [GLUE Benchmark leaderboard](https://gluebenchmark.com/leaderboard).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k8ge1L1IrJk"
      },
      "source": [
        "# Hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUdakNBhIrJl"
      },
      "outputs": [],
      "source": [
        "! pip install optuna\n",
        "! pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sgjdLKcIrJm"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71pt6N0eIrJo",
        "outputId": "5ba2f981-6a21-422b-d129-e6d3373d9e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/canine-c-finetuned-cola is already a clone of https://huggingface.co/dinalzein/canine-c-finetuned-cola. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[validation_key],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NboJ7kDOIrJq",
        "outputId": "4e6c4feb-dae6-4508-b8cf-cf881dce852f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-03-27 22:46:22,220]\u001b[0m A new study created in memory with name: no-name-50794803-50bd-4726-af43-1295c6580844\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2675\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2675' max='2675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2675/2675 06:06, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.613200</td>\n",
              "      <td>0.624533</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.609400</td>\n",
              "      <td>0.623943</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.608500</td>\n",
              "      <td>0.621228</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.608400</td>\n",
              "      <td>0.620064</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.610300</td>\n",
              "      <td>0.619751</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-0/checkpoint-535\n",
            "Configuration saved in canine-c-finetuned-cola/run-0/checkpoint-535/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-0/checkpoint-535/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-0/checkpoint-535/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-0/checkpoint-535/special_tokens_map.json\n",
            "tokenizer config file saved in canine-c-finetuned-cola/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-0/checkpoint-1070\n",
            "Configuration saved in canine-c-finetuned-cola/run-0/checkpoint-1070/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-0/checkpoint-1070/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-0/checkpoint-1070/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-0/checkpoint-1070/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-0/checkpoint-1605\n",
            "Configuration saved in canine-c-finetuned-cola/run-0/checkpoint-1605/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-0/checkpoint-1605/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-0/checkpoint-1605/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-0/checkpoint-1605/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-0/checkpoint-2140\n",
            "Configuration saved in canine-c-finetuned-cola/run-0/checkpoint-2140/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-0/checkpoint-2140/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-0/checkpoint-2140/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-0/checkpoint-2140/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-0/checkpoint-2675\n",
            "Configuration saved in canine-c-finetuned-cola/run-0/checkpoint-2675/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-0/checkpoint-2675/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-0/checkpoint-2675/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-0/checkpoint-2675/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-0/checkpoint-535 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 22:52:32,105]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 2.068234516547173e-06, 'num_train_epochs': 5, 'seed': 14, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 268\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [268/268 00:54, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.624367</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-1/checkpoint-268\n",
            "Configuration saved in canine-c-finetuned-cola/run-1/checkpoint-268/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-1/checkpoint-268/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-1/checkpoint-268/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-1/checkpoint-268/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-1/checkpoint-268 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 22:53:30,882]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 2.8012622014211212e-06, 'num_train_epochs': 1, 'seed': 2, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3207\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3207' max='3207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3207/3207 04:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.605700</td>\n",
              "      <td>0.628829</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.606500</td>\n",
              "      <td>0.618925</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.608300</td>\n",
              "      <td>0.618670</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-2/checkpoint-1069\n",
            "Configuration saved in canine-c-finetuned-cola/run-2/checkpoint-1069/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-2/checkpoint-1069/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-2/checkpoint-1069/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-2/checkpoint-1069/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-2/checkpoint-2138\n",
            "Configuration saved in canine-c-finetuned-cola/run-2/checkpoint-2138/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-2/checkpoint-2138/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-2/checkpoint-2138/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-2/checkpoint-2138/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-2/checkpoint-3207\n",
            "Configuration saved in canine-c-finetuned-cola/run-2/checkpoint-3207/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-2/checkpoint-3207/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-2/checkpoint-3207/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-2/checkpoint-3207/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-2/checkpoint-1069 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 22:58:22,159]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 3.7826875775515015e-05, 'num_train_epochs': 3, 'seed': 31, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 134\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='134' max='134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [134/134 00:48, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.617921</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-3/checkpoint-134\n",
            "Configuration saved in canine-c-finetuned-cola/run-3/checkpoint-134/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-3/checkpoint-134/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-3/checkpoint-134/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-3/checkpoint-134/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-3/checkpoint-134 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 22:59:13,974]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'learning_rate': 5.728584623180728e-05, 'num_train_epochs': 1, 'seed': 5, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4276\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4276' max='4276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4276/4276 05:02, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.625400</td>\n",
              "      <td>0.620574</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.626000</td>\n",
              "      <td>0.639653</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-4/checkpoint-2138\n",
            "Configuration saved in canine-c-finetuned-cola/run-4/checkpoint-2138/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-4/checkpoint-2138/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-4/checkpoint-2138/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-4/checkpoint-2138/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-4/checkpoint-4276\n",
            "Configuration saved in canine-c-finetuned-cola/run-4/checkpoint-4276/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-4/checkpoint-4276/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-4/checkpoint-4276/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-4/checkpoint-4276/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-4/checkpoint-2138 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 23:04:19,057]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'learning_rate': 3.6508694306688633e-06, 'num_train_epochs': 2, 'seed': 4, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10690\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10690' max='10690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10690/10690 11:32, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>0.620024</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.616100</td>\n",
              "      <td>0.621107</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.608000</td>\n",
              "      <td>0.621400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.619500</td>\n",
              "      <td>0.620600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.612900</td>\n",
              "      <td>0.620881</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-5/checkpoint-2138\n",
            "Configuration saved in canine-c-finetuned-cola/run-5/checkpoint-2138/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-5/checkpoint-2138/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-5/checkpoint-2138/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-5/checkpoint-2138/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-5/checkpoint-4276\n",
            "Configuration saved in canine-c-finetuned-cola/run-5/checkpoint-4276/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-5/checkpoint-4276/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-5/checkpoint-4276/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-5/checkpoint-4276/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-5/checkpoint-6414\n",
            "Configuration saved in canine-c-finetuned-cola/run-5/checkpoint-6414/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-5/checkpoint-6414/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-5/checkpoint-6414/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-5/checkpoint-6414/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-5/checkpoint-8552\n",
            "Configuration saved in canine-c-finetuned-cola/run-5/checkpoint-8552/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-5/checkpoint-8552/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-5/checkpoint-8552/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-5/checkpoint-8552/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-5/checkpoint-10690\n",
            "Configuration saved in canine-c-finetuned-cola/run-5/checkpoint-10690/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-5/checkpoint-10690/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-5/checkpoint-10690/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-5/checkpoint-10690/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-5/checkpoint-2138 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 23:15:54,121]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'learning_rate': 4.098367598791829e-05, 'num_train_epochs': 5, 'seed': 36, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2140\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2140' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2140/2140 04:10, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.609300</td>\n",
              "      <td>0.620018</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.608800</td>\n",
              "      <td>0.618146</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.614200</td>\n",
              "      <td>0.623934</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.598200</td>\n",
              "      <td>0.631749</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-6/checkpoint-535\n",
            "Configuration saved in canine-c-finetuned-cola/run-6/checkpoint-535/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-6/checkpoint-535/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-6/checkpoint-535/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-6/checkpoint-535/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-6/checkpoint-1070\n",
            "Configuration saved in canine-c-finetuned-cola/run-6/checkpoint-1070/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-6/checkpoint-1070/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-6/checkpoint-1070/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-6/checkpoint-1070/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-6/checkpoint-1605\n",
            "Configuration saved in canine-c-finetuned-cola/run-6/checkpoint-1605/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-6/checkpoint-1605/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-6/checkpoint-1605/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-6/checkpoint-1605/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-6/checkpoint-2140\n",
            "Configuration saved in canine-c-finetuned-cola/run-6/checkpoint-2140/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-6/checkpoint-2140/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-6/checkpoint-2140/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-6/checkpoint-2140/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-6/checkpoint-535 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 23:20:07,387]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 3.446439304836402e-05, 'num_train_epochs': 4, 'seed': 5, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2138\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2138' max='2138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2138/2138 02:19, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.622900</td>\n",
              "      <td>0.621040</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-7/checkpoint-2138\n",
            "Configuration saved in canine-c-finetuned-cola/run-7/checkpoint-2138/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-7/checkpoint-2138/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-7/checkpoint-2138/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-7/checkpoint-2138/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-7/checkpoint-2138 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 23:22:29,531]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 8.053497747389543e-05, 'num_train_epochs': 1, 'seed': 11, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4276\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4276' max='4276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4276/4276 04:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.613400</td>\n",
              "      <td>0.627335</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.614300</td>\n",
              "      <td>0.623007</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-8/checkpoint-2138\n",
            "Configuration saved in canine-c-finetuned-cola/run-8/checkpoint-2138/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-8/checkpoint-2138/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-8/checkpoint-2138/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-8/checkpoint-2138/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-8/checkpoint-4276\n",
            "Configuration saved in canine-c-finetuned-cola/run-8/checkpoint-4276/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-8/checkpoint-4276/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-8/checkpoint-4276/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-8/checkpoint-4276/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-8/checkpoint-2138 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 23:27:10,970]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'learning_rate': 7.090220251150307e-06, 'num_train_epochs': 2, 'seed': 26, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2138\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2138' max='2138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2138/2138 02:19, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.606300</td>\n",
              "      <td>0.624228</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/run-9/checkpoint-2138\n",
            "Configuration saved in canine-c-finetuned-cola/run-9/checkpoint-2138/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/run-9/checkpoint-2138/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/run-9/checkpoint-2138/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/run-9/checkpoint-2138/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/run-9/checkpoint-2138 (score: 0.0).\n",
            "\u001b[32m[I 2022-03-27 23:29:33,230]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'learning_rate': 1.2788513629888086e-05, 'num_train_epochs': 1, 'seed': 27, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psi4JymeIrJs",
        "outputId": "13e92aed-66c8-4cf9-8b35-f7e97c103517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='0', objective=0.0, hyperparameters={'learning_rate': 2.068234516547173e-06, 'num_train_epochs': 5, 'seed': 14, 'per_device_train_batch_size': 16})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "best_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsJ6sqdGIrJu",
        "outputId": "3ee960d9-6c8b-45d8-a69b-d8a6bac08dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/google/canine-c/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6b093dfc17fa050a4c019e4c09e2741b9b033068d20773077495920af01a7579.71fffe7f3108fd2f56b687ac1950da52fbfa8d85b6a0f311454ba92945232018\n",
            "Model config CanineConfig {\n",
            "  \"_name_or_path\": \"google/canine-c\",\n",
            "  \"architectures\": [\n",
            "    \"CanineModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 57344,\n",
            "  \"downsampling_rate\": 4,\n",
            "  \"eos_token_id\": 57345,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"local_transformer_stride\": 128,\n",
            "  \"max_position_embeddings\": 16384,\n",
            "  \"model_type\": \"canine\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hash_buckets\": 16384,\n",
            "  \"num_hash_functions\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 16,\n",
            "  \"upsampling_kernel_size\": 4,\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/canine-c/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/23fa4a48e9a93261356f2a97970b5b64f3f1c27293af81002321be54c1f87414.6b1eb60bc4d60f7ebd767d23a166a848ec68ce9f7c503d7d6248a7495b24828d\n",
            "All model checkpoint weights were used when initializing CanineForSequenceClassification.\n",
            "\n",
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8551\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2675\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2675' max='2675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2675/2675 05:14, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Matthews Correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.613200</td>\n",
              "      <td>0.624533</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.609400</td>\n",
              "      <td>0.623943</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.608500</td>\n",
              "      <td>0.621228</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.608400</td>\n",
              "      <td>0.620064</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.610300</td>\n",
              "      <td>0.619751</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-535\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-535/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-535/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-535/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-535/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-1070\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-1070/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-1070/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-1070/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-1070/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-1605\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-1605/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-1605/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-1605/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-1605/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-2140\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-2140/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-2140/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-2140/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-2140/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `CanineForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `CanineForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1043\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to canine-c-finetuned-cola/checkpoint-2675\n",
            "Configuration saved in canine-c-finetuned-cola/checkpoint-2675/config.json\n",
            "Model weights saved in canine-c-finetuned-cola/checkpoint-2675/pytorch_model.bin\n",
            "tokenizer config file saved in canine-c-finetuned-cola/checkpoint-2675/tokenizer_config.json\n",
            "Special tokens file saved in canine-c-finetuned-cola/checkpoint-2675/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from canine-c-finetuned-cola/checkpoint-535 (score: 0.0).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2675, training_loss=0.6102783602420415, metrics={'train_runtime': 314.4352, 'train_samples_per_second': 135.974, 'train_steps_per_second': 8.507, 'total_flos': 2370458675224140.0, 'train_loss': 0.6102783602420415, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "for n, v in best_run.hyperparameters.items():\n",
        "    setattr(trainer.args, n, v)\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CoLA_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02be246af64c4c82b7004217144d61d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d7496d0d66749e7904865b5d00d2899",
              "IPY_MODEL_3c594033badb4267bbf3694fe6dd1062",
              "IPY_MODEL_50df72f44a2f4c49b33f28d47226635f"
            ],
            "layout": "IPY_MODEL_396e9763ab254227bcf345068de90bc9"
          }
        },
        "5d7496d0d66749e7904865b5d00d2899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77521db7ddb54f0198f63dc4938e3af7",
            "placeholder": "​",
            "style": "IPY_MODEL_adf8947925894b89803b23ae282fa29b",
            "value": "100%"
          }
        },
        "3c594033badb4267bbf3694fe6dd1062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab64adc47584295a6d9fb77a563cd65",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11c72992c7a2416eaac88da8a4a72c22",
            "value": 9
          }
        },
        "50df72f44a2f4c49b33f28d47226635f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8788a8a276654e2da0279c396791b44f",
            "placeholder": "​",
            "style": "IPY_MODEL_adc757921aea4faea796417c1a120abc",
            "value": " 9/9 [00:00&lt;00:00,  8.68ba/s]"
          }
        },
        "396e9763ab254227bcf345068de90bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77521db7ddb54f0198f63dc4938e3af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf8947925894b89803b23ae282fa29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab64adc47584295a6d9fb77a563cd65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c72992c7a2416eaac88da8a4a72c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8788a8a276654e2da0279c396791b44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc757921aea4faea796417c1a120abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d436eda08748beab0645da61c29bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ab4beef4d324b2aac786cd7aa07f01f",
              "IPY_MODEL_13e2577fb58d4e7eae5c813438fab530",
              "IPY_MODEL_961bbaa500e741f5a7b6b895fd9d9343"
            ],
            "layout": "IPY_MODEL_ca6cbf7cf2ec4aa39edf2c9961ef61b6"
          }
        },
        "6ab4beef4d324b2aac786cd7aa07f01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe4fa0dd6bc844e191de3f877a936600",
            "placeholder": "​",
            "style": "IPY_MODEL_5533ae797aa54dfab8eda42dfb39f997",
            "value": "100%"
          }
        },
        "13e2577fb58d4e7eae5c813438fab530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f22547f55a24852901bdc7ddd7728ed",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3268f2b7e79344e29613341e167142f4",
            "value": 2
          }
        },
        "961bbaa500e741f5a7b6b895fd9d9343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eb3287358014d259dca90477cb4b0d3",
            "placeholder": "​",
            "style": "IPY_MODEL_ac1ef07541404f4e981423a73695e341",
            "value": " 2/2 [00:00&lt;00:00,  7.13ba/s]"
          }
        },
        "ca6cbf7cf2ec4aa39edf2c9961ef61b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4fa0dd6bc844e191de3f877a936600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5533ae797aa54dfab8eda42dfb39f997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f22547f55a24852901bdc7ddd7728ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3268f2b7e79344e29613341e167142f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eb3287358014d259dca90477cb4b0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac1ef07541404f4e981423a73695e341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a8ca7ce5cb4633acfd7a806ffadb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d4805015b734505bf41675b9583e9e7",
              "IPY_MODEL_e276b589bc1141b9b8f4a2178740b9d2",
              "IPY_MODEL_b5189dbedf914989a9ae731b199be6b2"
            ],
            "layout": "IPY_MODEL_83f17266ffb045b3a650f20d4d1a4a2d"
          }
        },
        "5d4805015b734505bf41675b9583e9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df42a620ea4148b9a4226e9db3874980",
            "placeholder": "​",
            "style": "IPY_MODEL_caf533fe81d242358deeaa205f2a8fe0",
            "value": "100%"
          }
        },
        "e276b589bc1141b9b8f4a2178740b9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44abe24f331e4620b4023114a9ca345c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a09ec2f6c03b4810833da26265f4767b",
            "value": 2
          }
        },
        "b5189dbedf914989a9ae731b199be6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7d8e1d1d5e4083b642c1746fdc3698",
            "placeholder": "​",
            "style": "IPY_MODEL_579a41fb139e4923a7c36dc9d1d30a9f",
            "value": " 2/2 [00:00&lt;00:00,  6.69ba/s]"
          }
        },
        "83f17266ffb045b3a650f20d4d1a4a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df42a620ea4148b9a4226e9db3874980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf533fe81d242358deeaa205f2a8fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44abe24f331e4620b4023114a9ca345c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09ec2f6c03b4810833da26265f4767b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e7d8e1d1d5e4083b642c1746fdc3698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579a41fb139e4923a7c36dc9d1d30a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b62c71425ee47318fd87e51c640b64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e89f52edb7114bf988c4bddcebcc8f2f",
              "IPY_MODEL_d4f7dc2bb0024550bf4b8a301115fa6f",
              "IPY_MODEL_e15a870a82e4496cb95aec1e117e4adc"
            ],
            "layout": "IPY_MODEL_a27ce3800d124daf8681dbd03a619c1f"
          }
        },
        "e89f52edb7114bf988c4bddcebcc8f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca15adc9f8714c5cb9028d310b51eed3",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e5e782c9884e45847566e3498c8a75",
            "value": "Downloading: 100%"
          }
        },
        "d4f7dc2bb0024550bf4b8a301115fa6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711c1c38b82b4f63966736c78e74924e",
            "max": 698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c57762f9b1df4544bff2375d4785825d",
            "value": 698
          }
        },
        "e15a870a82e4496cb95aec1e117e4adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9a618ad0c3458d8ef55ae22486b37f",
            "placeholder": "​",
            "style": "IPY_MODEL_f9993594943f4396be26018c9f3c0667",
            "value": " 698/698 [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "a27ce3800d124daf8681dbd03a619c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca15adc9f8714c5cb9028d310b51eed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e5e782c9884e45847566e3498c8a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711c1c38b82b4f63966736c78e74924e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57762f9b1df4544bff2375d4785825d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a9a618ad0c3458d8ef55ae22486b37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9993594943f4396be26018c9f3c0667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144464a357b64a30a8accf75bdc729f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d155b5340c749478244f73604af1dad",
              "IPY_MODEL_0c55b5326dc441de9eb2e8f8a3720e99",
              "IPY_MODEL_7f12148a7e824024aa65e8f1feaef953"
            ],
            "layout": "IPY_MODEL_d147c794ec05440dbe9a02988e4264d2"
          }
        },
        "8d155b5340c749478244f73604af1dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea710aa1e3c044f8afe7e35723711bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_d187d2d9751d4a43b37fbb247c88b2a8",
            "value": "Downloading: 100%"
          }
        },
        "0c55b5326dc441de9eb2e8f8a3720e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43b8cb7525474850898c927dbc428cbe",
            "max": 528561767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c28371db2764cbba3c3d973508c1e57",
            "value": 528561767
          }
        },
        "7f12148a7e824024aa65e8f1feaef953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24849132db94f6b8142644852645df2",
            "placeholder": "​",
            "style": "IPY_MODEL_d9ddac17da494652becfebbbe045b6e6",
            "value": " 504M/504M [00:10&lt;00:00, 30.8MB/s]"
          }
        },
        "d147c794ec05440dbe9a02988e4264d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea710aa1e3c044f8afe7e35723711bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d187d2d9751d4a43b37fbb247c88b2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43b8cb7525474850898c927dbc428cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c28371db2764cbba3c3d973508c1e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a24849132db94f6b8142644852645df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ddac17da494652becfebbbe045b6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}